---
title: "Kalman Filtering the Polls"
author: "Alex Nelson"
date: "7/5/2020"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(lubridate)
library(truncnorm)
library(MASS)
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

Despite the name, a "Kalman filter" doesn't _filter_. It's more of a "guess-and-check"-er.

```{r}
polls_2016 <- read_csv("../data/polling/all_polls_2016.csv",
                       col_types = cols(
                           .default = col_character(),
  X1 = col_double(),
  start.date = col_date(format = ""),
  end.date = col_date(format = ""),
  entry.date.time..et. = col_datetime(format = ""),
  number.of.observations = col_double(),
  trump = col_double(),
  clinton = col_double(),
  other = col_double(),
  undecided = col_double(),
  question.iteration = col_double(),
  johnson = col_double(),
  mcmullin = col_double()
                       ))
```

## Simple filtering

So, the control vector would be the `entry.date.time..et.` date, because it's an external impulse.

```{r}
mi_2016 <- polls_2016 %>%
  filter(state == "MI") %>%
  arrange(entry.date.time..et.)

election_date <- ymd("2016-11-08")
```

We transform this into approximately normal variables

```{r}
mi_clinton <- mi_2016 %>%
  filter(partisan != "Pollster") %>%
  mutate(clinton_mu = (clinton/100),
         clinton_sd = qnorm(0.999)*sqrt(((clinton/100)*(1 - clinton/100) + (1 - (clinton+trump)/100)**2)/number.of.observations),
         t = 1+as.integer(end.date - min(mi_2016$end.date)))
```

```{r}
get_for_state <- function(state_str) {
  polls_2016 %>%
  filter(state == state_str) %>%
  arrange(entry.date.time..et.) %>%
  filter(partisan != "Pollster") %>%
  mutate(clinton_mu = (clinton/100),
         sd = qnorm(0.999)*sqrt(((clinton/100)*(1 - clinton/100) + (1 - (clinton+trump)/100)**2)/number.of.observations),
         clinton_sd = sd,
         t = 1+as.integer(end.date - min(mi_2016$end.date)),
         precision = 1/clinton_sd**2)
}
```

```{r}
pool_polls <- function(df) {
  df %>%
    group_by(t) %>%
    summarize(clinton_pooled = weighted.mean(clinton/100, precision),
              trump_pooled = weighted.mean(trump/100, precision),
              trump = 100*trump_pooled,
              clinton = 100*clinton_pooled,
              sd = sqrt(1/sum(precision)),
              number.of.observations = sum(number.of.observations),
              end.date = first(end.date),
              number_of_polls = n()) %>%
    arrange(t)
}
```


```{r}
kalman_filter <- function(df, mu, sd, election_dt = election_date, h=1, f=1) {
  q = mean(df$sd)
  end_T <- as.integer(election_dt - min(df$end.date))
  x <- c(rnorm(1, 0.5, mean(df$sd)))
  p <- c(q)
  residual <- c()
  z <- rep(NA, end_T)
  r <- rep(NA, end_T)
  for (i in 1:nrow(df)) {
    z[df$t[i]] <- mu[i]
    r[df$t[i]] <- sd[i]
  }
  for (i in 1:end_T) {
    if (is.na(z[i])) {
      # random walk
      x <- c(x, rtruncnorm(1, a=0, b=1, mean=f*last(x), sd=q))
    } else {
      # predict
      x_pred <- f*last(x);
      p_pred <- f*last(p)*f + q;
      # correct
      y <- z[i] - h*x_pred;
      s <- h*p_pred*h + mean(r[1:i], na.rm=T);
      k <- p_pred*h/s;
      x <- c(x, x_pred + k*y)
      p <- c(p, (1 - k*h)*p_pred)
      residual <- c(residual, z[i] - h*last(x))
    }
  }
  list(x=x,
       p=p,
       residuals=residual)
}
```

```{r}
estimate_win <- function(df, n=100) {
  mean(replicate(last(kalman_filter(df, df$trump_pooled, df$sd)$x), n=n)  < replicate(last(kalman_filter(df, df$clinton_pooled, df$sd)$x), n=n))
}
```

# Refined Model

This time, lets use a multinomial distribution to describe a poll, then use the (multivariate) normal approximation which will be our `z[k]`. This will give us a normal variable `x[k][DEM]` for the estimated support for the Democratic candidate, and another `x[k][REP]` for the Republican candidate. Third party supporters become noise (more or less)...well, due to the quirkiness of the normal approximation to the multinomial, it's singular in nature (meaning: we can write `third_party = 1 - dem - rep` for the proportions), so we have an extra variable (`third_party`) that's not needed. (Just like real life.)


```{r}
multinomial_covariance_mat <- function(prob_vec, size) {
  mat <- matrix(data = prob_vec %*% t(prob_vec),
              nrow=length(prob_vec))*size;
  for (i in 1:length(prob_vec)) {
    mat[i,i] <- prob_vec[i]*(1 - prob_vec[i])
  }
  mat
}

norm_approx <- function(poll_df, cutoff_date = election_date) {
  poll_df %>%
    filter(end.date < cutoff_date) %>%
    transmute(p_clinton = clinton/100,
              p_trump = trump/100,
              p_third = 1 - p_clinton - p_trump,
              precision = (qnorm(0.975)*0.5/sqrt(number.of.observations))**-2,
              start_date = start.date,
              end_date = end.date,
              published = as.Date(entry.date.time..et.),
              size = number.of.observations,
              state = state,
              population = population
              ) %>%
    group_by(state,end_date) %>%
    summarize(p_clinton = weighted.mean(p_clinton, precision),
              p_trump = weighted.mean(p_trump, precision),
              p_third = weighted.mean(p_third, precision),
              precision = sum(precision),
              size = sum(size),
              mu_clinton = size*p_clinton,
              mu_trump = size*p_trump,
              mu_third = size*p_third,
              .groups = "drop")
}
```

Now, the `x_hat[k, k-1]` will need to be re-scaled to match the polling results, which is what happens with the `H[k]` matrix.

```{r}
make_h <- function(new_size, existing_size) {
  diag(new_size/existing_size, ncol=2, nrow=2)
}
```


```{r}
full_kalman <- function(df) {
  end_T <- as.integer(election_date - min(df$end_date))
  xs <- list()
  xs[[1]] <- (matrix(data=c(1600,1400,600), ncol=1))
  covariance_matrices <- list()
  covariance_matrices[[1]] <- 10000*matrix(data=c(50,-1/10,-1,
                                            -1/10,50,-1,
                                            -1,-1,5), nrow=3)
  residuals <- list()
  p <- list()
  
  
  for (i in 1:nrow(df)) {
    # estimate
    x_est <- last(xs)
    Q_mat <- diag((qnorm(0.975)**2)*0.5*df$size[i], 3);
    if (i > 1) {
      Q_mat <- Q_mat + multinomial_covariance_mat(c(df$p_clinton[i],
                                          df$p_trump[i],
                                          df$p_third[i]),
                                        size  = df$size[i])
    }
    P_est <- last(covariance_matrices) + Q_mat
    
    # predict
    z <- matrix(data=c(df$mu_clinton[i], df$mu_trump[i], df$mu_third[i]), ncol=1)
    
    h <- diag(1, nrow=3)
    if (i>1) {
      h <- diag(df$size[i]/max(df$size[i-1],sum(x_est)), 3)
      # print(df$size[i]/max(df$size[i-1],sum(x_est)))
    }
    
    y <- z - (h %*% x_est)
    
    R_mat <- multinomial_covariance_mat(c(df$p_clinton[i],
                                          df$p_trump[i],
                                          df$p_third[i]),
                                        size  = df$size[i]) +
      diag((qnorm(0.975)**2)*0.5*df$size[i], 3);
    R_mat[3,c(1,2)] <- 0; R_mat[c(1,2),3] <- 0;
    s <- (h %*% P_est %*% t(h)) + R_mat
    kalman_gain <- P_est %*% t(h) %*% solve(s)
    
    x_hat <- matrix(data=(x_est + (kalman_gain %*% y)), ncol=1)
    xs[[length(xs)+1]] <- x_hat
    p[[length(p) + 1]] <- x_hat/df$size[i]
    
    P_mat <- (diag(1, 3) - (kalman_gain %*% h)) %*% P_est %*% t((diag(1, 3) - (kalman_gain %*% h)))
    P_mat <- P_mat + (kalman_gain %*% R_mat %*% t(kalman_gain))
    covariance_matrices[[length(covariance_matrices)+1]] <- P_mat
    
    residuals[[length(residuals)+1]] <- (z - (h %*% x_hat))
  }
  #days_since_last_poll <- as.integer(election_date - last(df$end_date))
  #if (days_since_last_poll > 0 && abs(det(last(covariance_matrices))) > 1e-4) {
  #  x_hat <- MASS::mvrnorm(n=1, last(xs), last(covariance_matrices)*sqrt(days_since_last_poll))
  #  xs[[length(xs)+1]] <- matrix(data=x_hat, ncol=1)
  #}
  
  list(x = xs,
       p_mat = covariance_matrices,
       prob = p,
       residuals = residuals)
}
```

We then can transform the result into a probability of winning

```{r}
prob_dem_win <- function(results) {
  mu <- last(results$x)
  sigma <- last(results$p_mat)
  c <- matrix(data = c(1,-1,-1/2), ncol=1)
  s2 <- t(c) %*% sigma %*% c
  pnorm(0.5, t(c) %*% mu, sd=sqrt(abs(s2)), lower.tail=F)
}
```

```{r}
mean_sd <- function(results) {
  s <- 0
  for(x in results$x) {
    s <- s + x
  }
  mu <- s/length(results$x)
  s2 <- 0
  for(x in results$x) {
    s2 <- s2 + (x - mu)**2
  }
  list(var = s2/length(results$x),
       mean = mu)
}
```

```{r}
run_2016 <- function() {
  results <- list();
  for (state in unique(polls_2016$state)) {
    if (state != "--") {
      polls <- norm_approx(get_for_state(state));
      if (nrow(polls) > 1) {
        results[[state]] <- prob_dem_win(full_kalman(polls))
      }
    }
  }
  results;
}
```